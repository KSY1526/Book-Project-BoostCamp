{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna FFDCN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import argparse\n",
    "import warnings\n",
    "import joblib\n",
    "from src import seed_everything\n",
    "\n",
    "from src.data import context_data_load, context_data_split, context_data_loader\n",
    "\n",
    "from src import FFDCNModel\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = argparse.Namespace()\n",
    "with open('config.json','rt') as f:\n",
    "    args.__dict__.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmdataset = context_data_load(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    seed_everything(args.SEED)\n",
    "    args.BATCH_SIZE = trial.suggest_categorical('BATCH_SIZE',[256, 512, 1024])\n",
    "    args.EPOCHS = 1 #trial.suggest_int('EPOCH',5,10)\n",
    "    args.LR = trial.suggest_loguniform('LR',0.001,0.01)\n",
    "    args.WEIGHT_DECAY = trial.suggest_loguniform('WEIGHT_DECAY',1e-07,5e-06)\n",
    "    args.FFM_EMBED_DIM = trial.suggest_int('FFM_EMBED_DIM', 3, 32)\n",
    "    args.DCN_EMBED_DIM = trial.suggest_int('DCN_EMBED_DIM', 1, 16)\n",
    "    DCN_MLP_DIM_LAYERS = trial.suggest_int('DCN_MLP_DIM_LAYERS',1,3)\n",
    "    args.DCN_MLP_DIMS = [trial.suggest_int('DCN_MLP_DIM_NUM',1,16)]*DCN_MLP_DIM_LAYERS\n",
    "    args.DCN_DROPOUT = trial.suggest_categorical(\"DCN_DROPOUT\",[0.2,0.25,0.3])\n",
    "    args.DCN_NUM_LAYERS = trial.suggest_int('DCN_NUM_LAYERS',1 , 4)\n",
    "    # args.USER_N_D = trial.suggest_int('USER_N_D',0,3)\n",
    "    # args.USER_F_D = trial.suggest_int('USER_N_F',3,6)\n",
    "    # args.ISBN_N_D = trial.suggest_categorical('ISBN_N_D',[12,14,16,18,20,22])\n",
    "    # args.ISBN_N_F = trial.suggest_int('ISBN_N_F',28,32)\n",
    "    # ffmdataset = context_data_load(args)\n",
    "    dataffm = context_data_split(args,ffmdataset)\n",
    "    dataffm = context_data_loader(args,dataffm)\n",
    "    model = FFDCNModel(args,dataffm)\n",
    "    model.train()\n",
    "    log_score = model.predict_train()\n",
    "    \n",
    "    return log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=49)\n",
    "study = optuna.create_study(\n",
    "    study_name = 'FFDCN_parameter_opt',\n",
    "    direction = 'minimize',\n",
    "    sampler = sampler,\n",
    ")\n",
    "study.optimize(objective, n_trials=200)\n",
    "print(\"Best Score:\",study.best_value)\n",
    "print(\"Best trial\",study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.get_trials()[-1].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study,'./valid/studysave1003.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jl = joblib.load('./valid/studysave1003.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jl.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold for FFDCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import argparse\n",
    "import warnings\n",
    "import joblib\n",
    "from src import seed_everything\n",
    "\n",
    "from src.data import context_data_load, context_data_split, context_data_loader\n",
    "\n",
    "from src import FFDCNModel\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = argparse.Namespace()\n",
    "with open('config.json','rt') as f:\n",
    "    args.__dict__.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = context_data_load(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = []\n",
    "for train_idx, valid_idx in skf.split(data['train'].drop(['rating'], axis=1), data['train']['rating']):\n",
    "    folds.append((train_idx, valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffdcn_predicts = []\n",
    "for fold in range(5):\n",
    "    seed_everything(42)\n",
    "    print('='*15,fold+1,'='*15)\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    # Fold i Data Split\n",
    "    X_train = data['train'].drop(['rating'], axis=1).iloc[train_idx]\n",
    "    X_valid = data['train'].drop(['rating'], axis=1).iloc[valid_idx]\n",
    "    y_train = data['train']['rating'][train_idx]\n",
    "    y_valid = data['train']['rating'][valid_idx]\n",
    "    # Create Fold i Dataloader\n",
    "    fold_data = {\n",
    "            'X_train':X_train,\n",
    "            'X_valid':X_valid,\n",
    "            'y_train':y_train,\n",
    "            'y_valid':y_valid,\n",
    "            'test':data['test'],\n",
    "            'field_dims':data['field_dims'],\n",
    "            'sub':data['sub'],\n",
    "            'idx2user':data['idx2user'],\n",
    "            'idx2isbn':data['idx2isbn']\n",
    "    }\n",
    "    fold_data = context_data_loader(args,fold_data)\n",
    "    # Create Fold i FFDCN Model and train\n",
    "    print(f'--------------- {args.MODEL} TRAINING ---------------')\n",
    "    model = FFDCNModel(args,fold_data)\n",
    "    model.train()\n",
    "    log_score = model.predict_train()\n",
    "\n",
    "    # Fold i Model's Predict Test data\n",
    "    print(f'--------------- {args.MODEL} PREDICT ---------------')\n",
    "    predicts = model.predict(fold_data['test_dataloader'])\n",
    "    ffdcn_predicts.append(predicts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold i Save Predicted test data\n",
    "print(f'--------------- SAVE {args.MODEL} PREDICT ---------------')\n",
    "submission = pd.read_csv(args.DATA_PATH + 'sample_submission.csv')\n",
    "for fold_predict in ffdcn_predicts:\n",
    "    submission['rating'] += np.array(fold_predict) / 5\n",
    "submission.loc[submission['rating']>10,'rating'] = 10.0\n",
    "now = time.localtime()\n",
    "now_date = time.strftime('%Y%m%d', now)\n",
    "now_hour = time.strftime('%X', now)\n",
    "save_time = now_date + '_' + now_hour.replace(':', '')\n",
    "#submission.to_csv('submit/5fold_{}_{}.csv'.format(save_time, args.MODEL), index=False)\n",
    "submission.to_csv('submit/FFDCN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
